# NLP Paper

1. BERT [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)
2. Language Model [A Neural Probabilistic Language Model](https://github.com/AaronWong/notes/blob/master/deep_learning/paper/pdf/A_Neural_Probabilistic_Language_Model.pdf)
3. Attention [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
4. GELUS [GAUSSIAN ERROR LINEAR UNITS (GELUS)](https://arxiv.org/pdf/1606.08415.pdf)
5. Seq2Seq [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/pdf/1409.3215.pdf)
6. Bahadanau Attention [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/pdf/1409.0473.pdf)
7. OPT
8. OPT 2.0
